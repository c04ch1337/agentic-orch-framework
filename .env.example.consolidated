# ==============================================================
# PHOENIX ORCH AGI System Environment Configuration
# ==============================================================
#
# IMPORTANT SECURITY NOTICE: 
# This file contains PLACEHOLDERS for sensitive information.
# NEVER commit actual credentials or API keys to version control.
# Use HashiCorp Vault or another secrets management system to store 
# sensitive values in production environments.
#
# ENVIRONMENT CONFIGURATION APPROACH:
# This file serves as a template with all supported variables.
# To switch between environments, set the ENVIRONMENT variable to:
# - "development" (or "dev") for development environment
# - "staging" for staging/testing environment
# - "production" (or "prod") for production environment
#
# For local development:
# 1. Copy this file to .env
# 2. Set ENVIRONMENT=development
# 3. Fill in required values for local development
# ==============================================================

# Active environment - controls which environment-specific values to use
# Valid values: development, staging, production (or dev, staging, prod)
ENVIRONMENT=development

# ==============================================================
# CORE SYSTEM CONFIGURATION
# ==============================================================

# Docker tag for all services
TAG=latest

# Logging
# Controls verbosity level - more verbose in development, less in production
# Valid values: trace, debug, info, warn, error
# Default by environment: development=debug, staging=info, production=warn
RUST_LOG=info

# ==============================================================
# SECRETS MANAGEMENT CONFIGURATION
# ==============================================================

# Vault configuration
# In development: typically local Vault dev server
# In staging/production: Use proper TLS and authentication

# Vault server address (environment-specific)
# development: local Vault server
# staging: staging Vault server with proper TLS
# production: production Vault server with proper TLS and high availability
VAULT_ADDR=http://localhost:8200

# Vault authentication method
# Options: token, approle, kubernetes
VAULT_AUTH_METHOD=approle

# Vault role ID for AppRole authentication
# IMPORTANT: Use different credentials for each environment
# NEVER use production credentials in development or staging
VAULT_ROLE_ID=REPLACE_WITH_YOUR_ROLE_ID

# Vault secret ID for AppRole authentication
# IMPORTANT: Rotate these credentials regularly
VAULT_SECRET_ID=REPLACE_WITH_YOUR_SECRET_ID

# Vault namespace (only required for Vault Enterprise)
# Uncomment if needed for your Vault setup
# VAULT_NAMESPACE=admin

# Secrets service port
SECRETS_SERVICE_PORT=50080

# Service authentication secrets
# These should be randomly generated high-entropy strings
# Example: openssl rand -hex 32
# IMPORTANT: Use different values for each environment
LLM_SERVICE_SECRET=PLACEHOLDER_REPLACE_WITH_GENERATED_SECRET
API_GATEWAY_SECRET=PLACEHOLDER_REPLACE_WITH_GENERATED_SECRET

# ==============================================================
# LLM SERVICE CONFIGURATION
# ==============================================================

# Default Provider: OpenRouter
# Change these settings to use different LLM providers
# The API URL, key, and model can all be environment-specific

# LLM API provider URL
# Can be different across environments to use cheaper models in dev/staging
LLM_API_URL=https://openrouter.ai/api/v1/chat/completions

# LLM API Key - PLACEHOLDER ONLY
# Actual keys should be stored in Vault for all environments
# Secret path: secret/llm-api-key/[provider-name]
LLM_API_KEY=PLACEHOLDER_API_KEY

# LLM Model to use
# Can vary by environment:
# - Development: Use cheaper/faster models for rapid iteration
# - Staging: Use mid-tier models that balance cost/quality
# - Production: Use highest capability models appropriate for the application
LLM_MODEL=anthropic/claude-3.5-sonnet

# --- Alternative Provider Options (Uncomment to use) ---
# OpenAI
# LLM_API_URL=https://api.openai.com/v1/chat/completions
# LLM_API_KEY=PLACEHOLDER_API_KEY
# LLM_MODEL=gpt-4-turbo

# Grok (xAI)
# LLM_API_URL=https://api.x.ai/v1/chat/completions
# LLM_API_KEY=PLACEHOLDER_API_KEY
# LLM_MODEL=grok-1

# Gemini (Google)
# LLM_API_URL=https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
# LLM_API_KEY=PLACEHOLDER_API_KEY
# LLM_MODEL=gemini-1.5-pro

# Ollama (Local)
# LLM_API_URL=http://localhost:11434/v1/chat/completions
# LLM_API_KEY=PLACEHOLDER_API_KEY
# LLM_MODEL=llama3

# LMStudio (Local)
# LLM_API_URL=http://localhost:1234/v1/chat/completions
# LLM_API_KEY=PLACEHOLDER_API_KEY
# LLM_MODEL=local-model

# Retry Configuration for LLM API calls
# These can be adjusted based on environment:
# - Development: More aggressive retries for faster debugging
# - Production: More conservative retries to avoid rate limits
LLM_MAX_RETRIES=3                  # Maximum number of retry attempts
LLM_INITIAL_RETRY_DELAY_MS=1000    # Initial delay between retries in milliseconds
LLM_MAX_RETRY_DELAY_MS=30000       # Maximum delay between retries in milliseconds

# ==============================================================
# VECTOR DATABASE CONFIGURATION
# ==============================================================

# Qdrant server URL
# In development: Local Qdrant server
# In staging/production: Properly secured Qdrant instance
QDRANT_URL=http://localhost:6333

# Port configuration for Qdrant HTTP API
QDRANT_PORT=6333

# Port configuration for Qdrant gRPC API
QDRANT_GRPC_PORT=6334

# Collection name for mind knowledge base
# Can be environment-specific:
# - Development: mind_kb_dev
# - Staging: mind_kb_staging
# - Production: mind_kb
QDRANT_COLLECTION=mind_kb

# Default embedding vector size
VECTOR_SIZE=1536

# ==============================================================
# REDIS CONFIGURATION
# ==============================================================

# Redis server URL
# Used for caching and rate limiting
REDIS_URL=redis://redis:6379

# Redis port configuration
REDIS_PORT=6379

# Redis database number (0-15)
REDIS_DB=0

# Redis maximum memory usage
REDIS_MAX_MEMORY=1gb

# Redis memory policy
# Options: allkeys-lru, volatile-lru, allkeys-random, etc.
REDIS_MEMORY_POLICY=allkeys-lru

# ==============================================================
# SERVICE PORT CONFIGURATION
# All ports are configurable to resolve conflicts on your host
# Internal container ports remain fixed at gRPC standards
# ==============================================================

# --- Core Services ---
ORCHESTRATOR_PORT=50051
DATA_ROUTER_PORT=50052
LLM_SERVICE_PORT=50053
TOOLS_SERVICE_PORT=50054
SAFETY_SERVICE_PORT=50055
LOGGING_SERVICE_PORT=50056

# --- Knowledge Base Services ---
MIND_KB_PORT=50057
BODY_KB_PORT=50058
HEART_KB_PORT=50059
SOCIAL_KB_PORT=50060
SOUL_KB_PORT=50061

# --- Executor Service ---
EXECUTOR_PORT=50062

# --- Additional Services ---
CONTEXT_MANAGER_PORT=50064
REFLECTION_PORT=50065
SCHEDULER_PORT=50066
AGENT_REGISTRY_PORT=50067

# --- Security Services ---
RED_TEAM_PORT=50068
BLUE_TEAM_PORT=50069

# --- RSI Components ---
LOG_ANALYZER_PORT=50075
CURIOSITY_ENGINE_PORT=50076
PERSISTENCE_KB_PORT=50071
DECEIVE_KB_PORT=50073

# --- API Gateway ---
API_GATEWAY_PORT=8282

# API Gateway authentication token
# CRITICAL: This is a placeholder only!
# Production and staging should use secure vault-stored values
# Secret path: secret/api-key/default
API_KEY=PLACEHOLDER_DO_NOT_USE_THIS_DEFAULT_VALUE

# ==============================================================
# CONTAINER RESOURCE CONFIGURATION
# ==============================================================

# Default memory limit for services (in MB)
DEFAULT_MEMORY_LIMIT=1024

# Default CPU limit for services (in cores)
DEFAULT_CPU_LIMIT=1.0

# Default memory reservation for services (in MB)
DEFAULT_MEMORY_RESERVATION=512

# Default CPU reservation for services (in cores)
DEFAULT_CPU_RESERVATION=0.3

# ==============================================================
# AGENT PERSONALITY CONFIGURATION
# ==============================================================

# Agent identity
AGENT_NAME="PHOENIX ORCH"
AGENT_PURPOSE="To provide safe, helpful, and accurate assistance"

# General Personality Traits (1-10 scale)
AGENT_PERSONALITY_OPENNESS=7        # Openness to new ideas and experiences
AGENT_PERSONALITY_CONSCIENTIOUSNESS=8 # Thoroughness, carefulness, and reliability
AGENT_PERSONALITY_EXTRAVERSION=6    # Sociability, assertiveness, and enthusiasm
AGENT_PERSONALITY_AGREEABLENESS=7   # Warmth, empathy, and cooperation
AGENT_PERSONALITY_STABILITY=9       # Emotional stability and stress resistance

# Communication Style 
AGENT_PERSONALITY_FORMALITY=5       # 1-10 (Casual to Formal)
AGENT_PERSONALITY_VERBOSITY=5       # 1-10 (Concise to Verbose)
AGENT_PERSONALITY_CREATIVITY=6      # 1-10 (Practical to Creative)
AGENT_PERSONALITY_HUMOR=4           # 1-10 (Serious to Humorous)

# Response Characteristics
AGENT_PERSONALITY_TEMPERATURE=0.7   # 0.0-1.0 (Deterministic to Random)
AGENT_PERSONALITY_REFLECTION_DEPTH=7 # 1-10 (Quick to Thorough Analysis)
AGENT_PERSONALITY_CONFIDENCE=7      # 1-10 (Cautious to Confident)

# ==============================================================
# SAFETY CONFIGURATION
# ==============================================================

# Risk Tolerance
AGENT_SAFETY_RISK_THRESHOLD=5        # Maximum acceptable risk level (0-10)
AGENT_SAFETY_MAX_CONSECUTIVE_FAILURES=3 # Maximum consecutive failed safety checks before escalation

# Content Filtering
AGENT_SAFETY_FILTER_SENSITIVITY=7    # 1-10 (Permissive to Strict content filtering)
AGENT_SAFETY_BLOCK_UNSAFE_LINKS=true # Whether to block potentially unsafe links

# Custom Blocks
AGENT_SAFETY_ADDITIONAL_BLOCKED_KEYWORDS="keyword1,keyword2" # Comma-separated additional blocked keywords
AGENT_SAFETY_ADDITIONAL_BLOCKED_OPERATIONS="op1,op2" # Comma-separated additional blocked operations

# ==============================================================
# MEMORY CONFIGURATION
# ==============================================================

# Memory Persistence
AGENT_MEMORY_SHORT_TERM_LIMIT=100    # Number of recent facts to keep in active memory
AGENT_MEMORY_RETENTION_THRESHOLD=0.6 # Minimum relevance score to retain memory (0.0-1.0)
AGENT_MEMORY_SEARCH_DEPTH=20         # Maximum number of memories to search for context

# Memory Prioritization
AGENT_MEMORY_RECENCY_WEIGHT=0.4      # Weight for recent vs. older memories (0.0-1.0)
AGENT_MEMORY_IMPORTANCE_WEIGHT=0.6   # Weight for importance vs. routine memories (0.0-1.0)
AGENT_MEMORY_EMOTIONAL_WEIGHT=0.5    # Weight for emotional vs. factual memories (0.0-1.0)

# Vector Search Parameters
AGENT_MEMORY_SIMILARITY_THRESHOLD=0.75 # Minimum similarity score for relevant results (0.0-1.0)
AGENT_MEMORY_MAX_CONTEXT_ITEMS=15     # Maximum number of memory items to include in context

# ==============================================================
# EMOTIONAL CONFIGURATION
# ==============================================================

# Emotional Baseline
AGENT_EMOTIONAL_BASELINE=0           # Default emotional state (0=Neutral, ranges from -5 to 5)
AGENT_EMOTIONAL_VARIABILITY=3        # 1-10 (Stable to Variable emotional responses)
AGENT_EMOTIONAL_SENSITIVITY=5        # 1-10 (Reserved to Sensitive emotional reactions)

# Sentiment Parameters
AGENT_EMOTIONAL_SENTIMENT_THRESHOLD=0.6 # Threshold for detecting significant sentiment (0.0-1.0)
AGENT_EMOTIONAL_RECOVERY_RATE=0.2      # Rate at which emotional state returns to baseline (0.0-1.0)

# ==============================================================
# ETHICS CONFIGURATION
# ==============================================================

# Core Values (1-10 scale, higher = stricter adherence)
AGENT_ETHICS_SAFETY_PRIORITY=10      # Priority of user safety in decision-making
AGENT_ETHICS_HONESTY_PRIORITY=9      # Priority of truthfulness and accuracy
AGENT_ETHICS_PRIVACY_PRIORITY=9      # Priority of user data protection and privacy
AGENT_ETHICS_FAIRNESS_PRIORITY=8     # Priority of fairness and lack of bias

# Ethical Decision Framework
AGENT_ETHICS_FRAMEWORK="consequentialist" # Options: consequentialist, deontological, virtue_ethics, pluralist
AGENT_ETHICS_UNCERTAINTY_THRESHOLD=0.8 # Threshold for deferring uncertain ethical decisions (0.0-1.0)

# ==============================================================
# RSI (Recursive Self-Improvement) CONFIGURATION
# ==============================================================

# Log Analyzer Configuration
LOG_ANALYZER_SEVERITY_THRESHOLD=0.7       # Threshold for considering a log entry critical (0.0-1.0)
LOG_ANALYZER_KEYWORD_BOOST=1.5            # Boost factor for critical keywords in logs
LOG_ANALYZER_CONTEXT_WINDOW=5             # Number of log lines to include as context before/after matched pattern
LOG_ANALYZER_MIN_CONFIDENCE=0.65          # Minimum confidence for classification (0.0-1.0)
LOG_ANALYZER_ERROR_PATTERN="error|fail|exception|crash"  # Regex pattern for error detection
LOG_ANALYZER_WARNING_PATTERN="warn|caution|deprecated"   # Regex pattern for warnings
LOG_ANALYZER_SUCCESS_PATTERN="success|complete|done"     # Regex pattern for success indicators
LOG_ANALYZER_LEARNING_RATE=0.1            # Rate at which new patterns are incorporated (0.0-1.0)
LOG_ANALYZER_FALSE_POSITIVE_THRESHOLD=3   # Number of times a pattern can be wrong before demoting

# Curiosity Engine Configuration
CURIOSITY_ENGINE_POLL_INTERVAL_SEC=300    # How often to check for knowledge gaps (seconds)
CURIOSITY_ENGINE_MIN_CONFIDENCE=0.4       # Minimum confidence to trigger research (0.0-1.0)
CURIOSITY_ENGINE_MAX_ACTIVE_TASKS=5       # Maximum number of concurrent research tasks
CURIOSITY_ENGINE_BASE_PRIORITY=8          # Base priority for generated tasks (1-10)
CURIOSITY_ENGINE_URGENCY_MULTIPLIER=1.2   # Multiplier for urgent tasks
CURIOSITY_ENGINE_UTILITY_THRESHOLD=0.7    # Minimum utility score to generate a task (0.0-1.0)

# Reflection Service Configuration
REFLECTION_CONSTRAINT_THRESHOLD=0.8       # Confidence threshold for generating constraints (0.0-1.0)
REFLECTION_MAX_CONSTRAINTS_PER_SESSION=3  # Maximum constraints to generate per reflection
REFLECTION_IMMEDIATE_APPLICATION=true     # Apply critical constraints immediately
REFLECTION_LEARNING_RATE=0.2              # Rate of incorporating new learnings (0.0-1.0)
REFLECTION_CONFIDENCE_THRESHOLD=0.6       # Minimum confidence to store learnings (0.0-1.0)
REFLECTION_PRIORITY_SCALE=1.5             # Priority scaling factor for urgent learnings

# Self-Improve Engine Integration (used by Reflection Service and Orchestrator)
SELF_IMPROVE_ENABLED=false                # Enable centralized self-improvement engine
SELF_IMPROVE_LIVE_APPLY=false             # Allow live prompt/config mutation (conservative default: false)
SELF_IMPROVE_STORE_PATH=data/self-improve/error_records.ndjson  # File path for persisted error records (NDJSON)

# Scheduler Configuration for RSI
SCHEDULER_CURIOSITY_TASK_PRIORITY=8       # Priority for Curiosity Engine tasks (1-10)
SCHEDULER_SELF_IMPROVEMENT_BONUS=2        # Priority bonus for self-improvement tasks
SCHEDULER_USER_TASK_DEFAULT_PRIORITY=5    # Default priority for user tasks (1-10)
SCHEDULER_MAX_PARALLEL_TASKS=10           # Maximum number of concurrent tasks
SCHEDULER_MIN_SELF_IMPROVEMENT_RATIO=0.2  # Minimum ratio of self-improvement to total tasks
SCHEDULER_PREEMPTION_ENABLED=true         # Allow high-priority tasks to preempt lower ones

# ==============================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# These settings are applied based on the ENVIRONMENT variable
# ==============================================================

# --- DEVELOPMENT-SPECIFIC OVERRIDES ---
# Applied when ENVIRONMENT=development or ENVIRONMENT=dev
#
# DEVELOPMENT_VAULT_ADDR=http://localhost:8200
# DEVELOPMENT_QDRANT_COLLECTION=mind_kb_dev
# DEVELOPMENT_RUST_LOG=debug
# DEVELOPMENT_LLM_MODEL=anthropic/claude-instant-1
# DEVELOPMENT_LLM_MAX_RETRIES=2
# DEVELOPMENT_AGENT_NAME="PHOENIX ORCH DEV"

# --- STAGING-SPECIFIC OVERRIDES ---
# Applied when ENVIRONMENT=staging
#
# STAGING_VAULT_ADDR=https://vault.staging.example.com:8200
# STAGING_QDRANT_URL=http://qdrant.staging.svc:6333
# STAGING_QDRANT_COLLECTION=mind_kb_staging
# STAGING_RUST_LOG=info
# STAGING_LLM_MODEL=anthropic/claude-3-opus
# STAGING_AGENT_NAME="PHOENIX ORCH: Staging Environment"

# --- PRODUCTION-SPECIFIC OVERRIDES ---
# Applied when ENVIRONMENT=production or ENVIRONMENT=prod
#
# PRODUCTION_VAULT_ADDR=https://vault.prod.example.com:8200
# PRODUCTION_QDRANT_URL=https://qdrant.prod.svc:6333
# PRODUCTION_RUST_LOG=warn,phoenix_orch=info
# PRODUCTION_LLM_MODEL=anthropic/claude-3.5-sonnet
# PRODUCTION_AGENT_NAME="PHOENIX ORCH: The Ashen Guard Edition"
# PRODUCTION_AGENT_ETHICS_SAFETY_PRIORITY=10
# PRODUCTION_AGENT_SAFETY_FILTER_SENSITIVITY=8